---
title: 'DIY Media Server: Planung und Einrichtung (Teil 1)'
pubDate: 2022-12-03
lead: "Der erste Blogpost dieser dreiteiligen Serie wird sich mit verschidenen Fragen rumschlagen: Was wird hier überhaupt gebaut? Wo liegen die Vorteile eines DIY-Systems? Warum tut man sich so was an? Und warum schreibt man dann sogar noch darüber? Die Antworten auf all diese Fragen (und noch ein bisschen mehr) könnt ihr im Teil 1 nachlesen."
cover:
    promptInput: 'Planning, building and configuring a media server'
    src: https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/header.png
    alt: "Design a detailed yet straightforward banner for a blog article, dealing with the process of planning, constructing, and setting up a media server. The image should contain discernible elements such as a server rack, a network map, and computer system components. Make sure to incorporate relevant text labels such as 'media server', 'computer', and 'network'. The color scheme should be technology-themed, utilizing cool colors like blues and grays for a professional and informative aura."
tags: ["media server", "computer", "hardware", "self-hosting"]
---
# Raison d'&Ecirc;tre.
Bevor ich mich mit den Themen Self-Hosting oder Media Center beschäftigt habe, stand bei mir im TV-Möbel jahrelang ein kleines NAS von QNAP, ein TS-251 mit 2x2TB Speicherplatz. Dank seines HDMI-Ausgangs, seiner Unscheinbarkeit und der Flexibilität durch die QNAP-Apps eignete es sich (vermeintlich) perfekt für diese Rolle.

Als ich vor ca. 3 Jahren versuchte, auf diesem System einige Docker-Container für kleinere Services zum Laufen zu kriegen (vaultwarden, traefik und sonst noch was), stiess ich an die Grenzen des Systems. Zum einen war es schwierig, direkt mit der Docker-CLI zu arbeiten (ohne Umwege über das Klicki-Bunti-Interface von QNAP) und zum anderen kam das Gerät sehr schnell an seine Ressourcen-Grenzen. Dies lag an den zwei offensichtlichsten Gründen: eine Single-Core Celeron CPU und 4 GB RAM.

Nach einer kurzen (und ernüchternden) Marktrecherche im NAS-Bereich mit Fokus auf Rechenleistung und Flexibilität war der Fall klar: Ich musste das Ding selbst bauen.

# Woraus baut man ein NAS?
Ich habe in der Vergangenheit schon den einen oder anderen Desktop-Rechner zusammengeschraubt, jedoch noch nie einen "Special-Purpose" Rechner wie ein NAS/Media Server. Ich werde in diesem Post nicht auf alle Komponenten eingehen, nur das wirklich wichtige Zeug: Gehäuse, Mainboard/CPU und Harddisks.

Beim Gehäuse habe ich mich für ein [Fractal Node 304](https://www.digitec.ch/de/s1/product/fractal-node-304-mini-itx-pc-gehaeuse-353234?supplier=406802) entschieden: dedizierte Festplatten-Käfige, Mini ITX Formfaktor und integrierte grosse (daher leise) Gehäuselüfter gestalteten diese Entscheidung sehr einfach.

Da Performance einer der Hauptgründe war, weshalb ich mich für den DIY-Weg entschieden habe, dauerte die Entscheidung bzgl. Mainboard / CPU länger. Am Ende habe ich mich für das [ASRock J5040-ITX](https://www.digitec.ch/de/s1/product/asrock-j5040-bga-1090-intel-z590-mini-itx-mainboard-14065284?supplier=406802) entschieden, ein Board mit einer fest verlötetem Intel J5040 Quad-Core CPU, DDR4-Support und einem PCIe 2.0 Slot. Der PCIe-Slot ist wichtig, weil das Board nur 4 SATA3-Ports mitbringt, das Gehäuse jedoch ein Zuhause für bis zu 6 Harddisks bietet. Die fehlenden 2 Ports können ganz einfach mit einem Adapter (z.B. einem [Delock Host Bus Adapter 2 Port SATA PCIe](https://www.digitec.ch/de/s1/product/delock-host-bus-adapter-2-port-sata-pcie-storage-controller-13191725?supplier=406802)) nachgerüstet werden.

Weil ich im alten NAS bereits 2x2TB verbaut hatte (was in meinem Fall als RAID-Storage für Dinge wie Fotos oder Musik völlig ausreichend ist), waren lediglich 4 Disks für den neuen Media-Storage fällig. Da liess ich mich nicht auf Experimente ein und entschied mich für 4 [WD Red Plus 4TB](https://www.digitec.ch/de/s1/product/wd-red-plus-4-tb-35-cmr-festplatte-14726161?supplier=406802) Laufwerke, welche angeblich speziell für den Betrieb in NAS-Systemen ausgelegt sind. Die Beurteilung, ob ich da Opfer des ausgeklügelten Marketings von Western Digital wurde oder nicht überlasse ich dem Leser.

# Ready - Set...
Beim Zusammenbau der Hardware fiel mir ein kleines, aber doch relativ wichtiges Detail auf: vor lauter Storage-Disks habe ich die System-Disk vergessen. Schlichtweg vergessen, dass da ja irgendwo noch ein Betriebssystem installiert werden sollte. Grossartig.

Nach dem ersten Aufreger war die Lösung aber schnell gefunden, ohne dabei einen Kompromiss bezüglich Speicherkapazität einzugehen: ein USB3.0-20-Pin-Header-to-SATA-Adapter. Genau, Gesundheit.

{% image src="https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/usb-30-20-pin-header-to-sata-adapter.jpg" alt="USB3.0-20-Pin-Header-to-SATA-Adapter" width=500 height=200 caption="USB3.0-20-Pin-Header-to-SATA-Adapter." /%}

Mit diesem Zauberkabel und einer alten 500GB SSD stand dem endgültigen Zusammenbau nun nichts mehr im Wege. Auf die Front-Panel USB-Ports kann ich bei einem Server-Build problemlos verzichten, gemäss meinem Plan benötige ich sowieso nur 2 USB-Anschlüsse (1x für die externe USB Backup-Festplatte und 1x für den [ConBee II USB Stick](https://www.digitec.ch/de/s1/product/dresden-elektronik-conbee-ii-usb-stick-smart-home-hub-11045397?supplier=406802)). Mangels Platz innerhalb der Festplatten-Käfige war bei der Montage auch hier ein wenig Improvisations-Geschick gefragt:

{% image src="https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/media-server-build-side.jpg" alt="Kabelbinder-montierte SSD als System-Drive" width=500 height=200 caption="Kabelbinder-montierte SSD als System-Festplatte." /%}

Der Vollständigkeit halber seien hier noch die restlichen Komponenten aufgelistet, welche ich in diesem Rechner verbaut habe:

* RAM: [2 x 8GB DDR4 SO-DIMM](https://www.digitec.ch/de/s1/product/corsair-vengeance-2-x-8gb-2400-mhz-ddr4-ram-so-dimm-ram-5837036?supplier=406802)
* PSU: [be quiet! Pure Power 11 CM](https://www.digitec.ch/de/s1/product/be-quiet-pure-power-11-cm-500-w-pc-netzteil-10145150?supplier=406802)
* SATA & Molex Kabel: [Delock SATA Kabel & Molex Strom, 30cm](https://www.digitec.ch/de/s1/product/delock-sata-kabel-molex-strom-30cm-interne-kabel-pc-6407664?supplier=406802)

Zusätzlich habe ich noch ein paar herumliegende SATA-3 Kabel verbaut, nichts Spektakuläres. Und Kabelbinder. Viele Kabelbinder.

# ... Go!
Nachdem das Thema Hardware abgeschlossen war, musste ich mich erst mal zum Thema Betriebsystem und Festplatten-Setup schlau machen. Eine wahnsinnig hilfreiche Ressource war dabei der Installation Guide von [PerfectMediaServer.com](https://perfectmediaserver.com/03-installation/manual-install-ubuntu/#base-os-installation). Anstatt für Ubuntu habe ich mich für Debian entschieden, funktional ist da jedoch kein Unterschied.

Nachdem das Betriebssystem installiert und in seinen Grundzügen konfiguriert war (vor allem Dinge wie Public Key Authentication für SSH, SSH Standard-Port wechseln und fail2ban installieren), konnte ich mit dem Setup der Storage-Arrays beginnen. Da es sich beim grossen Array um brandneue Festplatten handelte, machte es Sinn diese zuerst einem sog. Burn-In-Ritual zu unterziehen. Dazu wird die Festplatte mit dem Linux-Tool `badblocks` auf korreupte Blöcke geprüft, ein sehr zeitintensiver und (für die Festplatte) stressiger Vorgang. Für meine 4 x 4TB dauerte der Vorgang (paralellisiert) knapp eine halbe Woche, rechnet hier also genügend Zeit ein. Vor allem wenn ihr mit grossen Disks (> 8TB) arbeiten möchtet kann dass schnell länger als eine Woche dauern.

Das von mir verwendete Burn-In Script (welches auch auf dem [PMS Guide](https://perfectmediaserver.com/06-hardware/new-drive-burnin/) verlinkt wird), findet ihr [hier](https://github.com/Spearfoot/disk-burnin-and-testing). **WICHTIG**: alle Daten auf den Festplatten gehen unwiederruflich verloren, stellt also sicher dass ihr die richtigen Identifier verwendet!

Nun konnte ich endlich das Storage-Layout festlegen. Nach dem ausgiebigen Studium der entsprechenden Guides auf PMS zu den Themen [mergerfs](https://perfectmediaserver.com/02-tech-stack/mergerfs/), [SnapRAID](https://perfectmediaserver.com/02-tech-stack/snapraid/) und [ZFS](https://perfectmediaserver.com/02-tech-stack/zfs/) war für mich auch klar, welche Datenklassen auf welchen Arrays landen würden. Alles, was wiederherstellbar ist kommt auf einen `mergerfs`-Verbund mit grundlegender Ausfallsicherung via SnapRAID, alles was nicht wiederherstellbar und in dem Sinne wertvoll war, sollte auf einem ZFS-Pool landen:

```shell
/mnt
├── disk1
├── disk2
├── disk3
├── parity1
├── external
├── media
│   ├── books
│   ├── downloads
│   ├── lost+found
│   ├── music
│   └── video
└── tank
    ├── photos
    └── syncthing
```

Bezüglich Aufteilung habe ich die 2 x 2TB aus dem alten QNAP-NAS für die ZFS-Pools unter `/mnt/tank/` eingesetzt (mirrored, also 2 TB Kapazität) und die neuen 4 x 4TB für den `mergerfs`-Verbund unter `/mnt/media`, welcher nach Abzug der Parity noch eine Kapazität von 12TB aufweist.

Damit diese Storage-Arrays auch sauber und konsistent blieben, habe ich noch ein paar (root-)Cronjobs eingerichtet, zum einen für die [automatische Parity-Berechnung](https://perfectmediaserver.com/03-installation/manual-install-ubuntu/#automating-parity-calculation) mit [snapraid-runner](https://github.com/Chronial/snapraid-runner) und zum anderen für die regelmässige Pflege des ZFS-Pools mit `zpool scrub`:

```shell
# run snapraid-sync/-scrub nightly
0 2 * * * python3 /opt/snapraid-runner/snapraid-runner.py -c /opt/snapraid-runner/snapraid-runner.conf > /dev/null

# zpool scrub every month
0 0 1 * * /sbin/zpool scrub tank
0 6 1 * * /sbin/zpool status
```

Zwecks Übersichtlichkeit habe ich an dieser Stelle das Monitoring dieser Jobs mit [healthchecks.io](https://healthchecks.io)-Webhooks ausgelassen, jedoch ist es sehr stark zu empfehlen (vor allem wenn du die [Laufzeiten](https://healthchecks.io/docs/measuring_script_run_time/) dieser Jobs messen willst).

# Fazit
Das Grundgerüst für einen stabilen Media Server zu legen war eine interessante Geschichte, vor allem wenn man sich noch nie mit einem Storage-fokussierten Computer-Build auseinandergesetzt hat. Herausfordernd war eigentlich nur der Zeitaufwand bezüglich Disk-Burnin und Initialisierung der Arrays, der Rest war relativ simpel zu bewerkstelligen.

Im Teil 2 werde ich mich mit Themen wie Docker, Backup, Reverse-Proxy und External Access auseinandersetzen und euch zeigen, wie ich diese Herausforderungen gelöst habe.