---
title: 'DIY Media Server: Planung und Einrichtung (Teil 1)'
pubDate: 2024-02-02
lead: "Der erste Blogpost dieser dreiteiligen Serie wird sich mit verschidenen Fragen rumschlagen: Was wird hier überhaupt gebaut? Wo liegen die Vorteile eines DIY-Systems? Warum tut man sich so was an? Die Antworten auf all diese Fragen (und noch ein bisschen mehr) könnt ihr im Teil 1 nachlesen."
cover:
    promptInput: 'Planning, building and configuring a media server'
    src: https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/header.png
    alt: "Design a detailed yet straightforward banner for a blog article, dealing with the process of planning, constructing, and setting up a media server. The image should contain discernible elements such as a server rack, a network map, and computer system components. Make sure to incorporate relevant text labels such as 'media server', 'computer', and 'network'. The color scheme should be technology-themed, utilizing cool colors like blues and grays for a professional and informative aura."
tags: ["media server", "computer", "hardware", "self-hosting"]
---
# Raison d'&Ecirc;tre.
Bevor ich mich mit den Themen Self-Hosting oder Media Center beschäftigt habe, stand bei mir im TV-Möbel jahrelang ein kleines NAS von QNAP, ein TS-251 mit 2x2TB Speicherplatz. Dank seines HDMI-Ausgangs, seiner Unscheinbarkeit und der Flexibilität durch die QNAP-Apps eignete es sich (vermeintlich) perfekt für diese Rolle.

Als ich vor ca. 3 Jahren versuchte, auf diesem System einige Docker-Container für kleinere Services zum Laufen zu kriegen (vaultwarden, traefik und sonst noch was), stiess ich an die Grenzen des Systems. Zum einen war es schwierig, direkt mit der Docker-CLI zu arbeiten (ohne Umwege über das Klicki-Bunti-Interface von QNAP) und zum anderen kam das Gerät sehr schnell an seine Ressourcen-Grenzen. Dies lag an den zwei offensichtlichsten Gründen: eine Single-Core Celeron CPU und 4 GB RAM.

Nach einer kurzen (und ernüchternden) Marktrecherche im NAS-Bereich mit Fokus auf Rechenleistung und Flexibilität war der Fall klar: Ich musste das Ding selbst bauen.

# Woraus baut man ein NAS?
Ich habe in der Vergangenheit schon den einen oder anderen Desktop-Rechner zusammengeschraubt, jedoch noch nie einen "Special-Purpose" Rechner wie ein NAS/Media Server. Ich werde in diesem Post nicht auf alle Komponenten eingehen, nur das wirklich wichtige Zeug: Gehäuse, Mainboard/CPU und Harddisks.

Beim Gehäuse habe ich mich für ein [Fractal Node 304](https://www.digitec.ch/de/s1/product/fractal-node-304-mini-itx-pc-gehaeuse-353234?supplier=406802) entschieden: dedizierte Festplatten-Käfige, Mini ITX Formfaktor und integrierte grosse (daher leise) Gehäuselüfter gestalteten diese Entscheidung sehr einfach.

Da Performance einer der Hauptgründe war, weshalb ich mich für den DIY-Weg entschieden habe, dauerte die Entscheidung bzgl. Mainboard / CPU länger. Am Ende habe ich mich für das [ASRock J5040-ITX](https://www.digitec.ch/de/s1/product/asrock-j5040-bga-1090-intel-z590-mini-itx-mainboard-14065284?supplier=406802) entschieden, ein Board mit einer fest verlötetem Intel J5040 Quad-Core CPU, DDR4-Support und einem PCIe 2.0 Slot. Der PCIe-Slot ist wichtig, weil das Board nur 4 SATA3-Ports mitbringt, das Gehäuse jedoch ein Zuhause für bis zu 6 Harddisks bietet. Die fehlenden 2 Ports können ganz einfach mit einem Adapter (z.B. einem [Delock Host Bus Adapter 2 Port SATA PCIe](https://www.digitec.ch/de/s1/product/delock-host-bus-adapter-2-port-sata-pcie-storage-controller-13191725?supplier=406802)) nachgerüstet werden.

Weil ich im alten NAS bereits 2x2TB verbaut hatte (was in meinem Fall als RAID-Storage für Dinge wie Fotos oder Musik völlig ausreichend ist), waren lediglich 4 Disks für den neuen Media-Storage fällig. Da liess ich mich nicht auf Experimente ein und entschied mich für 4 [WD Red Plus 4TB](https://www.digitec.ch/de/s1/product/wd-red-plus-4-tb-35-cmr-festplatte-14726161?supplier=406802) Laufwerke, welche angeblich speziell für den Betrieb in NAS-Systemen ausgelegt sind. Die Beurteilung, ob ich da Opfer des ausgeklügelten Marketings von Western Digital wurde oder nicht überlasse ich dem Leser.

# Ready - Set...Oops...
Beim Zusammenbau der Hardware fiel mir ein kleines, aber doch relativ wichtiges Detail auf: vor lauter Storage-Disks habe ich die System-Disk vergessen. Schlichtweg vergessen, dass da ja irgendwo noch ein Betriebssystem installiert werden sollte. Grossartig.

Nach dem ersten Aufreger war die Lösung aber schnell gefunden, ohne dabei einen Kompromiss bezüglich Speicherkapazität einzugehen: ein USB3.0-20-Pin-Header-to-SATA-Adapter. Genau, Gesundheit.

{% image src="https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/usb-30-20-pin-header-to-sata-adapter.jpg" alt="USB3.0-20-Pin-Header-to-SATA-Adapter" width=500 height=200 caption="USB3.0-20-Pin-Header-to-SATA-Adapter." /%}

Mit diesem Zauberkabel und einer alten 500GB SSD stand dem endgültigen Zusammenbau nun nichts mehr im Wege. Auf die Front-Panel USB-Ports kann ich bei einem Server-Build problemlos verzichten, gemäss meinem Plan benötige ich sowieso nur 2 USB-Anschlüsse (1x für die externe USB Backup-Festplatte und 1x für den [ConBee II USB Stick](https://www.digitec.ch/de/s1/product/dresden-elektronik-conbee-ii-usb-stick-smart-home-hub-11045397?supplier=406802)). Mangels Platz innerhalb der Festplatten-Käfige war bei der Montage auch hier ein wenig Improvisations-Geschick gefragt:

{% image src="https://storage.schaermu.ch/blog/media-server-phase1-planung-und-setup/media-server-build-side.jpg" alt="Kabelbinder-montierte SSD als System-Drive" width=500 height=200 caption="Kabelbinder-montierte SSD als System-Festplatte." /%}

Der Vollständigkeit halber seien hier noch die restlichen Komponenten aufgelistet, welche ich in diesem Rechner verbaut habe:

* RAM: [2 x 8GB DDR4 SO-DIMM](https://www.digitec.ch/de/s1/product/corsair-vengeance-2-x-8gb-2400-mhz-ddr4-ram-so-dimm-ram-5837036?supplier=406802)
* PSU: [be quiet! Pure Power 11 CM](https://www.digitec.ch/de/s1/product/be-quiet-pure-power-11-cm-500-w-pc-netzteil-10145150?supplier=406802)
* SATA & Molex Kabel: [Delock SATA Kabel & Molex Strom, 30cm](https://www.digitec.ch/de/s1/product/delock-sata-kabel-molex-strom-30cm-interne-kabel-pc-6407664?supplier=406802)

Zusätzlich habe ich noch ein paar herumliegende SATA-3 Kabel verbaut, nichts Spektakuläres. Und Kabelbinder. Viele Kabelbinder.

# Storage-Setup
Nun, da das Thema Hardware abgeschlossen war, musste ich mich erst mal zum Thema Betriebsystem und Festplatten-Setup schlau machen. Eine wahnsinnig hilfreiche Ressource war dabei der Installation Guide von [PerfectMediaServer.com](https://perfectmediaserver.com/03-installation/manual-install-ubuntu/#base-os-installation). Anstatt für Ubuntu habe ich mich für Debian entschieden, funktional ist da jedoch kein Unterschied.

Nachdem das Betriebssystem installiert und in seinen Grundzügen konfiguriert war (vor allem Dinge wie Public Key Authentication für SSH, SSH Standard-Port wechseln und fail2ban installieren), konnte ich mit dem Setup der Storage-Arrays beginnen. Da es sich beim grossen Array um brandneue Festplatten handelte, machte es Sinn diese zuerst einem sog. Burn-In-Ritual zu unterziehen. Dazu wird die Festplatte mit dem Linux-Tool `badblocks` auf korreupte Blöcke geprüft, ein sehr zeitintensiver und (für die Festplatte) stressiger Vorgang. Für meine 4 x 4TB dauerte der Vorgang (paralellisiert) knapp eine halbe Woche, rechnet hier also genügend Zeit ein. Vor allem wenn ihr mit grossen Disks (> 8TB) arbeiten möchtet kann dass schnell länger als eine Woche dauern.

Das von mir verwendete Burn-In Script (welches auch auf dem [PMS Guide](https://perfectmediaserver.com/06-hardware/new-drive-burnin/) verlinkt wird), findet ihr [hier](https://github.com/Spearfoot/disk-burnin-and-testing). **WICHTIG**: alle Daten auf den Festplatten gehen unwiederruflich verloren, stellt also sicher dass ihr die richtigen Identifier verwendet!

Nun konnte ich endlich das Storage-Layout festlegen. Nach dem ausgiebigen Studium der entsprechenden Guides auf PMS zu den Themen [mergerfs](https://perfectmediaserver.com/02-tech-stack/mergerfs/), [SnapRAID](https://perfectmediaserver.com/02-tech-stack/snapraid/) und [ZFS](https://perfectmediaserver.com/02-tech-stack/zfs/) war für mich auch klar, welche Datenklassen auf welchen Arrays landen würden. Alles, was wiederherstellbar ist kommt auf einen `mergerfs`-Verbund mit grundlegender Ausfallsicherung via SnapRAID, alles was nicht wiederherstellbar und in dem Sinne wertvoll war, sollte auf einem ZFS-Pool landen:

```shell
/mnt
├── disk1
├── disk2
├── disk3
├── parity1
├── external
├── media
│   ├── books
│   ├── downloads
│   ├── lost+found
│   ├── music
│   └── video
└── tank
    ├── photos
    └── syncthing
```

Bezüglich Aufteilung habe ich die 2 x 2TB aus dem alten QNAP-NAS für die ZFS-Pools unter `/mnt/tank/` eingesetzt (mirrored, also 2 TB Kapazität) und die neuen 4 x 4TB für den `mergerfs`-Verbund unter `/mnt/media`, welcher nach Abzug der Parity noch eine Kapazität von 12TB aufweist.

Damit diese Storage-Arrays auch sauber und konsistent blieben, habe ich noch ein paar (root-)Cronjobs eingerichtet, zum einen für die [automatische Parity-Berechnung](https://perfectmediaserver.com/03-installation/manual-install-ubuntu/#automating-parity-calculation) mit [snapraid-runner](https://github.com/Chronial/snapraid-runner) und zum anderen für die regelmässige Pflege des ZFS-Pools mit `zpool scrub`:

```shell
# run snapraid-sync/-scrub nightly
0 2 * * * python3 /opt/snapraid-runner/snapraid-runner.py -c /opt/snapraid-runner/snapraid-runner.conf > /dev/null

# zpool scrub every month
0 0 1 * * /sbin/zpool scrub tank
0 6 1 * * /sbin/zpool status
```

Zwecks Übersichtlichkeit habe ich an dieser Stelle das Monitoring dieser Jobs mit [healthchecks.io](https://healthchecks.io)-Webhooks ausgelassen, jedoch ist es sehr stark zu empfehlen (vor allem wenn du die [Laufzeiten](https://healthchecks.io/docs/measuring_script_run_time/) dieser Jobs messen willst).

# Docker-Setup
Im Internet geistert eine Unmenge an Guides zu Themen wie Self-Hosting, Homelab oder Media Server rum. Die meisten beschäftigen sich mit super-komplexen, Ansible-automatisierten Bare-Metal Kubernetes-Deployments, bei welchen die Dienste via ArgoCD vollautomatisiert auf Basis eines Git-Repos synchronisiert werden. Obwohl so was natürlich interessant sein kann, ging es mir primär darum einen Nutzen zu generieren und nicht die maximal mögliche Zeit mit Rumbasteln und Neu-deployen zu verbringen. Aus diesem und ein paar anderen Gründen (Erfahrung, Einfachheit) habe ich mich für ein vergleichsweise simples Deployment mit `docker` und `docker compose` entschieden.

Bei der Installation von `docker` gibts eigentlich nur zwei Dinge zu beachten:
1) Installiert das korrekte System-Package (`docker-ce` vom offiziellen Docker-Repository), sonst werdet ihr je nachdem lange auf Updates warten.
2) Lasst Docker im rootless-Mode laufen, ihr reduziert dadurch das Potenzial für einen erfolgreichen Container-Escape erheblich.

## Installation
Zuerst werden mal alle notwendigen Voraussetzungen installiert:
```shell
$ sudo apt update && sudo apt install apt-transport-https ca-certificates curl gnupg2 software-properties-common
```
Im zweiten Schritt installieren wir den GPG-Key für das offizielle Docker-Repository und fügen selbiges hinzu:
```shell
$ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add -
$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable"
$ sudo apt update
```
Nun installieren wir sowohl `docker` sowie alle notwendigen Voraussetzungen für einen rootless-Betrieb. Zusätzlich fügen wir unseren non-root User zur Gruppe `docker` hinzu, damit wir nicht alle docker-Befehle als Root-User ausführen müssen: 
```shell
$ sudo apt install docker-ce slirp4netns fuse-overlayfs dbus-user-session uidmap
$ sudo usermod -aG docker ${USER}
```
## Konfiguration
Bevor wir nun alles entsprechend konfigurieren müssen wir uns kurz neu auf dem Server einloggen (wegen der Installation von `dbus-user-session`). Ist dies erledigt, sollte erst mal kurz geprüft werden, ob `docker` läuft und wir mit unserem unprivilegierten User entsprechend docker-Befehle ausführen können:
```shell
$ sudo systemctl status docker
● docker.service - Docker Application Container Engine
   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
   Active: active (running)...
$ docker info
Client: Docker Engine - Community
 Version:    25.0.3
 Context:    default
 Debug Mode: false
 Plugins:
  buildx: Docker Buildx (Docker Inc.)
    Version:  v0.12.1
    Path:     /usr/libexec/docker/cli-plugins/docker-buildx
  compose: Docker Compose (Docker Inc.)
    Version:  v2.24.5
    Path:     /usr/libexec/docker/cli-plugins/docker-compose
...
```
Sieht euer Output ähnlich aus, ist alles in Ordnung und wir können die Installation weiterführen. Dazu führen wir den Befehl `/usr/bin/dockerd-rootless-setuptool.sh install` aus, so wird `docker` auf rootless-Betrieb umgestellt. Beachtet dabei auch die Hinweise während das Skript durchläuft und führt Instruktionen entsprechend aus!

**HINWEIS**: falls dieses Shell-Script nicht vorhanden ist, könnt ihr es nachinstallieren, indem ihr die rootless-Extras installiert: `sudo apt-get install -y docker-ce-rootless-extras`

# Fazit
Das Grundgerüst für einen stabilen Media Server zu legen war eine interessante Geschichte, vor allem wenn man sich noch nie mit einem Storage-fokussierten Computer-Build auseinandergesetzt hat. Herausfordernd war eigentlich nur der Zeitaufwand bezüglich Disk-Burnin und Initialisierung der Arrays, der Rest war relativ simpel zu bewerkstelligen.

Im Teil 2 werde ich mich mit Themen wie Docker, Backup, Reverse-Proxy und External Access auseinandersetzen und euch zeigen, wie ich diese Herausforderungen gelöst habe.